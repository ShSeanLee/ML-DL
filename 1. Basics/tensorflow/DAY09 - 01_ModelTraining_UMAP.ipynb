{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35d1d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import scipy as sp\n",
    "import PIL\n",
    "\n",
    "# Tensorflow\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, ZeroPadding2D\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB6, ResNet50V2\n",
    "#from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "#import scikitplot as skplt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc4bc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "LearningRate = 0.001\n",
    "Decay = 0.000001\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "480dea9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "ResNet = tf.keras.applications.ResNet50(include_top=False,\n",
    "    weights='imagenet', input_tensor=None, input_shape=(img_width,img_height,3), pooling=None)\n",
    "# 마지막 prediction layer를 위한 작업\n",
    "\n",
    "GAP = GlobalAveragePooling2D()(ResNet.output)\n",
    "predictions = Dense(1, activation='sigmoid')(GAP)\n",
    "\n",
    "# Input ~ Output 연결해주기\n",
    "DeepLearning = Model(inputs=ResNet.input, outputs=predictions)\n",
    "\n",
    "# learning parameter를 더하여 최종 model compile\n",
    "DeepLearning.compile(optimizer=\n",
    "         SGD(lr=LearningRate, decay=Decay, momentum=0.9, nesterov=True), \n",
    "         loss='binary_crossentropy',\n",
    "         metrics=['acc']\n",
    ") # 나이를, MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48620a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            2049        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DeepLearning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d47d4d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online-augmentation 적용 Generator\n",
    "# 1. 이미지를 전부다 불러서 램 (메모리)에 올릴 수 없기 때문\n",
    "# 2. 이미지는 Augmentation을 해주는게 좋아서\n",
    "\n",
    "DATAGEN_TRAIN = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")\n",
    "\n",
    "# Online-augmentation 비적용 Generator (Test용)\n",
    "DATAGEN_TEST = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    data_format=\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9390d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 866 images belonging to 2 classes.\n",
      "Found 62 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generator의 instance 생성 (Train)\n",
    "TRAIN_GENERATOR = DATAGEN_TRAIN.flow_from_directory(\n",
    "    'Train',\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode= \"binary\",\n",
    "    subset = \"training\")\n",
    "\n",
    "# Generator의 instance 생성 (Test)\n",
    "TEST_GENERATOR = DATAGEN_TEST.flow_from_directory(\n",
    "    'Test',\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe19cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call-back 함수\n",
    "\n",
    "# CheckPoint: Epoch 마다 validation 성능을 검증하여, best performance 일 경우 저장\n",
    "CP = ModelCheckpoint(filepath='Model/ModelResNet50-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}.hdf5',\n",
    "            monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Learning Rate 줄여나가기\n",
    "LR = ReduceLROnPlateau(monitor='val_loss',factor=0.8,patience=3, verbose=1, min_lr=1e-8)\n",
    "\n",
    "CALLBACK = [CP, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fe7680f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_2840\\1784762658.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  DeepLearning.fit_generator(\n",
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - ETA: 0s - loss: 0.6187 - acc: 0.6640\n",
      "Epoch 1: val_acc improved from -inf to 0.59677, saving model to Model\\ModelResNet50-001-0.6894-0.5968.hdf5\n",
      "55/55 [==============================] - 151s 3s/step - loss: 0.6187 - acc: 0.6640 - val_loss: 0.6894 - val_acc: 0.5968 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.4686 - acc: 0.7864\n",
      "Epoch 2: val_acc did not improve from 0.59677\n",
      "55/55 [==============================] - 155s 3s/step - loss: 0.4686 - acc: 0.7864 - val_loss: 0.9408 - val_acc: 0.2903 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.4107 - acc: 0.8152\n",
      "Epoch 3: val_acc did not improve from 0.59677\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.4107 - acc: 0.8152 - val_loss: 1.7617 - val_acc: 0.2903 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.3913 - acc: 0.8256\n",
      "Epoch 4: val_acc improved from 0.59677 to 0.70968, saving model to Model\\ModelResNet50-004-0.6098-0.7097.hdf5\n",
      "55/55 [==============================] - 159s 3s/step - loss: 0.3913 - acc: 0.8256 - val_loss: 0.6098 - val_acc: 0.7097 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.3700 - acc: 0.8245\n",
      "Epoch 5: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 159s 3s/step - loss: 0.3700 - acc: 0.8245 - val_loss: 5.8998 - val_acc: 0.2903 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.3100 - acc: 0.8661\n",
      "Epoch 6: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 159s 3s/step - loss: 0.3100 - acc: 0.8661 - val_loss: 1.0746 - val_acc: 0.2903 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.3005 - acc: 0.8776\n",
      "Epoch 7: val_acc did not improve from 0.70968\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.3005 - acc: 0.8776 - val_loss: 4.0546 - val_acc: 0.2903 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2764 - acc: 0.8811\n",
      "Epoch 8: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.2764 - acc: 0.8811 - val_loss: 4.0141 - val_acc: 0.2903 - lr: 8.0000e-04\n",
      "Epoch 9/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2808 - acc: 0.8857\n",
      "Epoch 9: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.2808 - acc: 0.8857 - val_loss: 0.7133 - val_acc: 0.5323 - lr: 8.0000e-04\n",
      "Epoch 10/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2514 - acc: 0.9007\n",
      "Epoch 10: val_acc did not improve from 0.70968\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.2514 - acc: 0.9007 - val_loss: 0.9058 - val_acc: 0.7097 - lr: 8.0000e-04\n",
      "Epoch 11/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2216 - acc: 0.9065\n",
      "Epoch 11: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.2216 - acc: 0.9065 - val_loss: 1.0285 - val_acc: 0.3871 - lr: 6.4000e-04\n",
      "Epoch 12/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.8915\n",
      "Epoch 12: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.2732 - acc: 0.8915 - val_loss: 1.0948 - val_acc: 0.3871 - lr: 6.4000e-04\n",
      "Epoch 13/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2030 - acc: 0.9284\n",
      "Epoch 13: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.2030 - acc: 0.9284 - val_loss: 0.5698 - val_acc: 0.6774 - lr: 6.4000e-04\n",
      "Epoch 14/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1919 - acc: 0.9238\n",
      "Epoch 14: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1919 - acc: 0.9238 - val_loss: 0.9583 - val_acc: 0.7097 - lr: 6.4000e-04\n",
      "Epoch 15/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.2052 - acc: 0.9122\n",
      "Epoch 15: val_acc did not improve from 0.70968\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.2052 - acc: 0.9122 - val_loss: 0.8559 - val_acc: 0.7097 - lr: 6.4000e-04\n",
      "Epoch 16/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1636 - acc: 0.9365\n",
      "Epoch 16: val_acc did not improve from 0.70968\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1636 - acc: 0.9365 - val_loss: 0.9842 - val_acc: 0.7097 - lr: 6.4000e-04\n",
      "Epoch 17/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1794 - acc: 0.9261\n",
      "Epoch 17: val_acc improved from 0.70968 to 0.74194, saving model to Model\\ModelResNet50-017-0.9801-0.7419.hdf5\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1794 - acc: 0.9261 - val_loss: 0.9801 - val_acc: 0.7419 - lr: 5.1200e-04\n",
      "Epoch 18/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1794 - acc: 0.9238\n",
      "Epoch 18: val_acc did not improve from 0.74194\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1794 - acc: 0.9238 - val_loss: 1.2139 - val_acc: 0.7419 - lr: 5.1200e-04\n",
      "Epoch 19/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1555 - acc: 0.9330\n",
      "Epoch 19: val_acc improved from 0.74194 to 0.77419, saving model to Model\\ModelResNet50-019-1.1804-0.7742.hdf5\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.1555 - acc: 0.9330 - val_loss: 1.1804 - val_acc: 0.7742 - lr: 5.1200e-04\n",
      "Epoch 20/20\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1395 - acc: 0.9492\n",
      "Epoch 20: val_acc improved from 0.77419 to 0.79032, saving model to Model\\ModelResNet50-020-0.8393-0.7903.hdf5\n",
      "55/55 [==============================] - 158s 3s/step - loss: 0.1395 - acc: 0.9492 - val_loss: 0.8393 - val_acc: 0.7903 - lr: 4.0960e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c728814a30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Training Start\n",
    "DeepLearning.fit_generator(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        #steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        \n",
    "        epochs=20,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=TEST_GENERATOR)\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a596ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_2840\\3622694860.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  DeepLearning.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1469 - acc: 0.9434\n",
      "Epoch 1: val_acc did not improve from 0.79032\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1469 - acc: 0.9434 - val_loss: 0.7728 - val_acc: 0.7903 - lr: 4.0960e-04\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1459 - acc: 0.9446\n",
      "Epoch 2: val_acc improved from 0.79032 to 0.80645, saving model to Model\\ModelResNet50-002-0.6052-0.8065.hdf5\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.1459 - acc: 0.9446 - val_loss: 0.6052 - val_acc: 0.8065 - lr: 4.0960e-04\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1384 - acc: 0.9492\n",
      "Epoch 3: val_acc did not improve from 0.80645\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1384 - acc: 0.9492 - val_loss: 0.6263 - val_acc: 0.8065 - lr: 4.0960e-04\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1425 - acc: 0.9515\n",
      "Epoch 4: val_acc did not improve from 0.80645\n",
      "55/55 [==============================] - 157s 3s/step - loss: 0.1425 - acc: 0.9515 - val_loss: 0.6035 - val_acc: 0.7742 - lr: 4.0960e-04\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1139 - acc: 0.9584\n",
      "Epoch 5: val_acc improved from 0.80645 to 0.83871, saving model to Model\\ModelResNet50-005-0.6008-0.8387.hdf5\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1139 - acc: 0.9584 - val_loss: 0.6008 - val_acc: 0.8387 - lr: 4.0960e-04\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1331 - acc: 0.9503\n",
      "Epoch 6: val_acc did not improve from 0.83871\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1331 - acc: 0.9503 - val_loss: 0.4615 - val_acc: 0.8226 - lr: 4.0960e-04\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1063 - acc: 0.9596\n",
      "Epoch 7: val_acc did not improve from 0.83871\n",
      "55/55 [==============================] - 155s 3s/step - loss: 0.1063 - acc: 0.9596 - val_loss: 0.4750 - val_acc: 0.8387 - lr: 4.0960e-04\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1109 - acc: 0.9538\n",
      "Epoch 8: val_acc did not improve from 0.83871\n",
      "55/55 [==============================] - 155s 3s/step - loss: 0.1109 - acc: 0.9538 - val_loss: 0.5338 - val_acc: 0.8065 - lr: 4.0960e-04\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1155 - acc: 0.9492\n",
      "Epoch 9: val_acc did not improve from 0.83871\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1155 - acc: 0.9492 - val_loss: 0.5739 - val_acc: 0.7742 - lr: 4.0960e-04\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1417 - acc: 0.9480\n",
      "Epoch 10: val_acc did not improve from 0.83871\n",
      "55/55 [==============================] - 155s 3s/step - loss: 0.1417 - acc: 0.9480 - val_loss: 0.5636 - val_acc: 0.7903 - lr: 3.2768e-04\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1199 - acc: 0.9538\n",
      "Epoch 11: val_acc did not improve from 0.83871\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1199 - acc: 0.9538 - val_loss: 0.6428 - val_acc: 0.7903 - lr: 3.2768e-04\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 0.1396 - acc: 0.9446\n",
      "Epoch 12: val_acc improved from 0.83871 to 0.85484, saving model to Model\\ModelResNet50-012-0.4488-0.8548.hdf5\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.1396 - acc: 0.9446 - val_loss: 0.4488 - val_acc: 0.8548 - lr: 3.2768e-04\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m########## Training Start\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mDeepLearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTRAIN_GENERATOR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 데이터가 너무 클 경우 1-epoch을 못하는 경우\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCALLBACK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEST_GENERATOR\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2198\u001b[0m \u001b[38;5;124;03m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[0;32m   2199\u001b[0m \n\u001b[0;32m   2200\u001b[0m \u001b[38;5;124;03mDEPRECATED:\u001b[39;00m\n\u001b[0;32m   2201\u001b[0m \u001b[38;5;124;03m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[0;32m   2202\u001b[0m \u001b[38;5;124;03m  this endpoint.\u001b[39;00m\n\u001b[0;32m   2203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2204\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.fit_generator` is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2206\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed in a future version. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2207\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2208\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m-> 2209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## Training Start\n",
    "DeepLearning.fit_generator(\n",
    "        TRAIN_GENERATOR,\n",
    "        # 데이터가 너무 클 경우 1-epoch을 못하는 경우\n",
    "        #steps_per_epoch=TRAIN_GENERATOR.n / batch_size,\n",
    "        \n",
    "        epochs=50,\n",
    "        callbacks=CALLBACK,\n",
    "        shuffle=True, # Training에 패턴이 존재하면 overfit이 잘 되기 때문에, Shuffle 사용해야함. 단 test에는 절대 X\n",
    "        validation_data=TEST_GENERATOR)\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "316de4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLearning.load_weights('Model\\ModelResNet50-005-0.6008-0.8387.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "516d77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = DeepLearning.predict( TEST_GENERATOR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdaad1a5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5176020e-04],\n",
       "       [1.7520189e-03],\n",
       "       [5.2002072e-04],\n",
       "       [2.0761722e-01],\n",
       "       [3.2004714e-04],\n",
       "       [2.4615079e-02],\n",
       "       [5.0159097e-03],\n",
       "       [1.0420978e-03],\n",
       "       [2.7523637e-03],\n",
       "       [1.0392338e-02],\n",
       "       [1.5299201e-02],\n",
       "       [7.0359945e-01],\n",
       "       [2.0880252e-02],\n",
       "       [2.6226640e-03],\n",
       "       [6.4191222e-04],\n",
       "       [7.3577762e-03],\n",
       "       [7.9219818e-02],\n",
       "       [1.7589563e-01],\n",
       "       [7.4885190e-03],\n",
       "       [1.1614695e-01],\n",
       "       [1.4474988e-04],\n",
       "       [9.9380314e-01],\n",
       "       [6.8211555e-04],\n",
       "       [9.8968446e-03],\n",
       "       [4.2502317e-01],\n",
       "       [9.9015379e-01],\n",
       "       [1.0286748e-02],\n",
       "       [1.0430777e-01],\n",
       "       [1.1028647e-03],\n",
       "       [6.0733428e-06],\n",
       "       [4.8750560e-05],\n",
       "       [2.6941299e-04],\n",
       "       [1.6238183e-02],\n",
       "       [3.1581372e-02],\n",
       "       [5.3133070e-03],\n",
       "       [1.1140223e-07],\n",
       "       [4.0017581e-01],\n",
       "       [9.3934691e-01],\n",
       "       [9.8840266e-01],\n",
       "       [1.3820320e-01],\n",
       "       [4.9713969e-02],\n",
       "       [2.9296821e-01],\n",
       "       [2.4985254e-02],\n",
       "       [9.9795175e-01],\n",
       "       [9.2126715e-01],\n",
       "       [9.6744448e-02],\n",
       "       [3.1737834e-02],\n",
       "       [4.7096688e-01],\n",
       "       [9.5654523e-01],\n",
       "       [9.9899703e-01],\n",
       "       [9.9863899e-01],\n",
       "       [9.9591106e-01],\n",
       "       [9.9996966e-01],\n",
       "       [9.9995494e-01],\n",
       "       [9.9999905e-01],\n",
       "       [8.6999023e-01],\n",
       "       [6.8876648e-01],\n",
       "       [8.2005662e-01],\n",
       "       [8.1988996e-01],\n",
       "       [5.8857948e-01],\n",
       "       [1.5353051e-01],\n",
       "       [7.1430755e-01]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34a7a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = TEST_GENERATOR.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6113a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1a76cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc9b8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff002798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c7288692d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set up plotting area\n",
    "plt.figure(figsize=(10,10)).clf()\n",
    "\n",
    "#fit logistic regression model and plot ROC curve\n",
    "fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
    "auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "plt.plot(fpr,tpr,label= \"ResNet50, AUC=\"+str(auc))\n",
    "    \n",
    "#fit gradient boosted model and plot ROC curve\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4193902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DeepLearning_FeatureExtractor = Model(inputs=ResNet.input, outputs=GAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e714b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DeepLearning_FeatureExtractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e275589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "ExtractedFeatures = DeepLearning_FeatureExtractor.predict( TEST_GENERATOR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "faa34074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28720957, 0.19432615, 0.        , ..., 0.98330367, 0.17764463,\n",
       "        1.678068  ],\n",
       "       [0.16460465, 0.        , 0.08340592, ..., 0.21025027, 0.03798338,\n",
       "        0.7015661 ],\n",
       "       [0.2849901 , 0.72516227, 0.14409947, ..., 0.9360261 , 0.04256409,\n",
       "        0.45345408],\n",
       "       ...,\n",
       "       [0.24372272, 0.7835889 , 0.02991604, ..., 0.02076652, 0.411471  ,\n",
       "        0.10954386],\n",
       "       [0.35860172, 1.1689696 , 0.0117957 , ..., 0.07725359, 0.02722322,\n",
       "        0.07581027],\n",
       "       [0.6558482 , 0.05078056, 0.1743147 , ..., 0.1826718 , 0.17812608,\n",
       "        0.20087482]], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1738bfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benign\\\\B_001-0002-1.0.jpg',\n",
       " 'Benign\\\\B_001-0002-1.1.jpg',\n",
       " 'Benign\\\\B_001-0003-1.0.jpg',\n",
       " 'Benign\\\\B_001-0003-1.1.jpg',\n",
       " 'Benign\\\\B_001-0003-1.2.jpg',\n",
       " 'Benign\\\\B_001-0004-1.1.jpg',\n",
       " 'Benign\\\\B_001-0004-1.2.jpg',\n",
       " 'Benign\\\\B_001-0005-1.0.jpg',\n",
       " 'Benign\\\\B_001-0005-1.2.jpg',\n",
       " 'Benign\\\\B_001-0006-1.1.jpg',\n",
       " 'Benign\\\\B_001-0006-1.2.jpg',\n",
       " 'Benign\\\\B_001-0007-1.0.jpg',\n",
       " 'Benign\\\\B_001-0007-1.2.jpg',\n",
       " 'Benign\\\\B_001-0008-1.1.jpg',\n",
       " 'Benign\\\\B_001-0008-1.2.jpg',\n",
       " 'Benign\\\\B_001-0013-1.0.jpg',\n",
       " 'Benign\\\\B_001-0013-1.1.jpg',\n",
       " 'Benign\\\\B_001-0014-1.0.jpg',\n",
       " 'Benign\\\\B_001-0014-1.2.jpg',\n",
       " 'Benign\\\\B_001-0015-1.0.jpg',\n",
       " 'Benign\\\\B_001-0015-1.1.jpg',\n",
       " 'Benign\\\\B_001-0019-1.0.jpg',\n",
       " 'Benign\\\\B_001-0023-1.0.jpg',\n",
       " 'Benign\\\\B_001-0023-1.2.jpg',\n",
       " 'Benign\\\\B_001-0024-1.0.jpg',\n",
       " 'Benign\\\\B_001-0024-1.1.jpg',\n",
       " 'Benign\\\\B_001-0025-1.1.jpg',\n",
       " 'Benign\\\\B_001-0025-1.2.jpg',\n",
       " 'Benign\\\\B_001-0027-1.0.jpg',\n",
       " 'Benign\\\\B_001-0027-1.1.jpg',\n",
       " 'Benign\\\\B_001-0027-1.2.jpg',\n",
       " 'Benign\\\\B_001-0027-1.3.jpg',\n",
       " 'Benign\\\\B_001-0028-1.0.jpg',\n",
       " 'Benign\\\\B_001-0028-1.1.jpg',\n",
       " 'Benign\\\\B_001-0029-1.2.jpg',\n",
       " 'Benign\\\\B_001-0029-1.3.jpg',\n",
       " 'Benign\\\\B_001-0030-1.0.jpg',\n",
       " 'Benign\\\\B_001-0030-1.1.jpg',\n",
       " 'Benign\\\\B_001-0030-1.2.jpg',\n",
       " 'Benign\\\\B_001-0033-1.0.jpg6756.jpg',\n",
       " 'Benign\\\\B_001-0033-1.0.jpg8541.jpg',\n",
       " 'Benign\\\\B_001-0033-1.1.jpg',\n",
       " 'Benign\\\\B_001-0033-2.0.jpg1576.jpg',\n",
       " 'Benign\\\\B_001-0033-2.0.jpg2310.jpg',\n",
       " 'Cancer\\\\M_001-0001-1.0.jpg3870.jpg',\n",
       " 'Cancer\\\\M_001-0001-1.0.jpg838.jpg',\n",
       " 'Cancer\\\\M_001-0001-1.1.jpg6536.jpg',\n",
       " 'Cancer\\\\M_001-0001-1.1.jpg8006.jpg',\n",
       " 'Cancer\\\\M_001-0009-1.0.jpg',\n",
       " 'Cancer\\\\M_001-0009-1.0.jpg3323.jpg',\n",
       " 'Cancer\\\\M_001-0009-1.1.jpg7948.jpg',\n",
       " 'Cancer\\\\M_001-0009-1.1.jpg8468.jpg',\n",
       " 'Cancer\\\\M_001-0011-1.0.jpg',\n",
       " 'Cancer\\\\M_001-0011-1.1.jpg',\n",
       " 'Cancer\\\\M_001-0011-1.2.jpg',\n",
       " 'Cancer\\\\M_001-0017-1.0.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.0.jpg1612.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.0.jpg3309.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.1.jpg6291.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.1.jpg6612.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.2.jpg4663.jpg',\n",
       " 'Cancer\\\\M_001-0018-1.2.jpg8095.jpg']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_GENERATOR.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "da2eb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinalData = pd.DataFrame(ExtractedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "79d5e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = []\n",
    "for filename in TEST_GENERATOR.filenames:\n",
    "    ID.append(filename[9:].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e22c90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtractedFeatures_DF = pd.DataFrame(ExtractedFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c07b908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExtractedFeatures_DF['Subject'] = ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "65b0ef32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287210</td>\n",
       "      <td>0.194326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106927</td>\n",
       "      <td>0.377418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>1.064226</td>\n",
       "      <td>0.389456</td>\n",
       "      <td>0.584565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859810</td>\n",
       "      <td>0.449728</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.488186</td>\n",
       "      <td>0.763559</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.983304</td>\n",
       "      <td>0.177645</td>\n",
       "      <td>1.678068</td>\n",
       "      <td>001-0002-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.048911</td>\n",
       "      <td>0.890236</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.200687</td>\n",
       "      <td>1.360367</td>\n",
       "      <td>0.745493</td>\n",
       "      <td>0.273739</td>\n",
       "      <td>...</td>\n",
       "      <td>3.485157</td>\n",
       "      <td>1.629335</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.364728</td>\n",
       "      <td>0.145867</td>\n",
       "      <td>0.198063</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.701566</td>\n",
       "      <td>001-0002-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.284990</td>\n",
       "      <td>0.725162</td>\n",
       "      <td>0.144099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.011460</td>\n",
       "      <td>0.234903</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.140909</td>\n",
       "      <td>0.525270</td>\n",
       "      <td>0.112858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.189988</td>\n",
       "      <td>0.413721</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.167251</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>0.936026</td>\n",
       "      <td>0.042564</td>\n",
       "      <td>0.453454</td>\n",
       "      <td>001-0003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.449418</td>\n",
       "      <td>0.169543</td>\n",
       "      <td>0.021138</td>\n",
       "      <td>0.288096</td>\n",
       "      <td>0.090404</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.286722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.751390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.681070</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.545889</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.422505</td>\n",
       "      <td>001-0003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349064</td>\n",
       "      <td>1.007837</td>\n",
       "      <td>0.033174</td>\n",
       "      <td>0.025766</td>\n",
       "      <td>0.156556</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.040377</td>\n",
       "      <td>0.251204</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.316148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051137</td>\n",
       "      <td>0.253719</td>\n",
       "      <td>0.407803</td>\n",
       "      <td>0.068843</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.171881</td>\n",
       "      <td>0.292069</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>001-0003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.110216</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.025022</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>0.229831</td>\n",
       "      <td>0.173924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084275</td>\n",
       "      <td>1.449711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.626314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139727</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>0.715444</td>\n",
       "      <td>1.998464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.034171</td>\n",
       "      <td>001-0018-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635051</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>0.394440</td>\n",
       "      <td>1.374968</td>\n",
       "      <td>0.423758</td>\n",
       "      <td>0.123072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520479</td>\n",
       "      <td>1.790056</td>\n",
       "      <td>...</td>\n",
       "      <td>1.138621</td>\n",
       "      <td>0.764802</td>\n",
       "      <td>0.404869</td>\n",
       "      <td>0.101241</td>\n",
       "      <td>0.115668</td>\n",
       "      <td>2.456570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143507</td>\n",
       "      <td>0.051275</td>\n",
       "      <td>001-0018-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.243723</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.138603</td>\n",
       "      <td>0.508234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.553419</td>\n",
       "      <td>0.797945</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418822</td>\n",
       "      <td>0.255749</td>\n",
       "      <td>0.177682</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.630050</td>\n",
       "      <td>3.494973</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.411471</td>\n",
       "      <td>0.109544</td>\n",
       "      <td>001-0018-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.358602</td>\n",
       "      <td>1.168970</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.375434</td>\n",
       "      <td>0.451893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.781089</td>\n",
       "      <td>0.898645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419094</td>\n",
       "      <td>0.972701</td>\n",
       "      <td>0.079639</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.450286</td>\n",
       "      <td>2.476288</td>\n",
       "      <td>0.077254</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.075810</td>\n",
       "      <td>001-0018-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.655848</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.174315</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>0.441082</td>\n",
       "      <td>0.223644</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.612111</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123453</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>1.193960</td>\n",
       "      <td>0.357489</td>\n",
       "      <td>2.774895</td>\n",
       "      <td>0.182672</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>0.200875</td>\n",
       "      <td>001-0018-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.287210  0.194326  0.000000  0.106927  0.377418  0.000000  0.620755   \n",
       "1   0.164605  0.000000  0.083406  0.048911  0.890236  0.018433  0.200687   \n",
       "2   0.284990  0.725162  0.144099  0.000000  1.011460  0.234903  0.137286   \n",
       "3   1.449418  0.169543  0.021138  0.288096  0.090404  0.024157  0.286722   \n",
       "4   0.349064  1.007837  0.033174  0.025766  0.156556  0.094527  0.040377   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "57  0.110216  0.701317  0.025022  0.334997  0.619999  0.229831  0.173924   \n",
       "58  0.000000  0.635051  0.071822  0.394440  1.374968  0.423758  0.123072   \n",
       "59  0.243723  0.783589  0.029916  0.138603  0.508234  0.000000  0.000000   \n",
       "60  0.358602  1.168970  0.011796  0.375434  0.451893  0.000000  0.057861   \n",
       "61  0.655848  0.050781  0.174315  0.536645  0.441082  0.223644  0.000977   \n",
       "\n",
       "           7         8         9  ...      2039      2040      2041      2042  \\\n",
       "0   1.064226  0.389456  0.584565  ...  0.859810  0.449728  0.004866  0.488186   \n",
       "1   1.360367  0.745493  0.273739  ...  3.485157  1.629335  0.131944  0.364728   \n",
       "2   0.140909  0.525270  0.112858  ...  0.765385  0.189988  0.413721  0.135747   \n",
       "3   0.000000  0.074135  0.751390  ...  0.499493  0.000000  0.444929  0.000000   \n",
       "4   0.251204  0.420903  0.316148  ...  0.051137  0.253719  0.407803  0.068843   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "57  0.000000  0.084275  1.449711  ...  0.626314  0.000000  0.139727  0.058614   \n",
       "58  0.000000  0.520479  1.790056  ...  1.138621  0.764802  0.404869  0.101241   \n",
       "59  0.010886  0.553419  0.797945  ...  1.418822  0.255749  0.177682  0.036213   \n",
       "60  0.000000  1.781089  0.898645  ...  0.419094  0.972701  0.079639  0.031499   \n",
       "61  0.005634  0.612111  1.827969  ...  0.123453  0.003787  0.623986  1.193960   \n",
       "\n",
       "        2043      2044      2045      2046      2047     Subject  \n",
       "0   0.763559  0.035749  0.983304  0.177645  1.678068  001-0002-1  \n",
       "1   0.145867  0.198063  0.210250  0.037983  0.701566  001-0002-1  \n",
       "2   0.167251  0.011636  0.936026  0.042564  0.453454  001-0003-1  \n",
       "3   1.681070  0.029463  0.545889  0.082474  0.422505  001-0003-1  \n",
       "4   0.005900  0.171881  0.292069  0.025903  0.043729  001-0003-1  \n",
       "..       ...       ...       ...       ...       ...         ...  \n",
       "57  0.715444  1.998464  0.000000  0.038537  0.034171  001-0018-1  \n",
       "58  0.115668  2.456570  0.000000  0.143507  0.051275  001-0018-1  \n",
       "59  0.630050  3.494973  0.020767  0.411471  0.109544  001-0018-1  \n",
       "60  0.450286  2.476288  0.077254  0.027223  0.075810  001-0018-1  \n",
       "61  0.357489  2.774895  0.182672  0.178126  0.200875  001-0018-1  \n",
       "\n",
       "[62 rows x 2049 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExtractedFeatures_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "19937a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clinical = pd.read_csv(\"ClinicalInformation.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "79e72288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      001-0001-1\n",
       "1      001-0002-1\n",
       "2      001-0003-1\n",
       "3      001-0004-1\n",
       "4      001-0005-1\n",
       "          ...    \n",
       "160    002-0145-1\n",
       "161    002-0146-1\n",
       "162    002-0147-1\n",
       "163    002-0148-1\n",
       "164    002-0149-1\n",
       "Name: Subject, Length: 165, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clinical['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "35680252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     001-0002-1\n",
       "1     001-0002-1\n",
       "2     001-0003-1\n",
       "3     001-0003-1\n",
       "4     001-0003-1\n",
       "         ...    \n",
       "57    001-0018-1\n",
       "58    001-0018-1\n",
       "59    001-0018-1\n",
       "60    001-0018-1\n",
       "61    001-0018-1\n",
       "Name: Subject, Length: 62, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalData['Subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "10536b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged_ExtractedFeature_Clinical_DF = pd.merge(FinalData, Clinical, on = \"Subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6fe5aaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.287210</td>\n",
       "      <td>0.194326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106927</td>\n",
       "      <td>0.377418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620755</td>\n",
       "      <td>1.064226</td>\n",
       "      <td>0.389456</td>\n",
       "      <td>0.584565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859810</td>\n",
       "      <td>0.449728</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.488186</td>\n",
       "      <td>0.763559</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.983304</td>\n",
       "      <td>0.177645</td>\n",
       "      <td>1.678068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.164605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.048911</td>\n",
       "      <td>0.890236</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.200687</td>\n",
       "      <td>1.360367</td>\n",
       "      <td>0.745493</td>\n",
       "      <td>0.273739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.485157</td>\n",
       "      <td>1.629335</td>\n",
       "      <td>0.131944</td>\n",
       "      <td>0.364728</td>\n",
       "      <td>0.145867</td>\n",
       "      <td>0.198063</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.701566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.284990</td>\n",
       "      <td>0.725162</td>\n",
       "      <td>0.144099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.011460</td>\n",
       "      <td>0.234903</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.140909</td>\n",
       "      <td>0.525270</td>\n",
       "      <td>0.112858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.189988</td>\n",
       "      <td>0.413721</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.167251</td>\n",
       "      <td>0.011636</td>\n",
       "      <td>0.936026</td>\n",
       "      <td>0.042564</td>\n",
       "      <td>0.453454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.449418</td>\n",
       "      <td>0.169543</td>\n",
       "      <td>0.021138</td>\n",
       "      <td>0.288096</td>\n",
       "      <td>0.090404</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.286722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.751390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119580</td>\n",
       "      <td>0.499493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.681070</td>\n",
       "      <td>0.029463</td>\n",
       "      <td>0.545889</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.422505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349064</td>\n",
       "      <td>1.007837</td>\n",
       "      <td>0.033174</td>\n",
       "      <td>0.025766</td>\n",
       "      <td>0.156556</td>\n",
       "      <td>0.094527</td>\n",
       "      <td>0.040377</td>\n",
       "      <td>0.251204</td>\n",
       "      <td>0.420903</td>\n",
       "      <td>0.316148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048996</td>\n",
       "      <td>0.051137</td>\n",
       "      <td>0.253719</td>\n",
       "      <td>0.407803</td>\n",
       "      <td>0.068843</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.171881</td>\n",
       "      <td>0.292069</td>\n",
       "      <td>0.025903</td>\n",
       "      <td>0.043729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.110216</td>\n",
       "      <td>0.701317</td>\n",
       "      <td>0.025022</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>0.229831</td>\n",
       "      <td>0.173924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084275</td>\n",
       "      <td>1.449711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051454</td>\n",
       "      <td>0.626314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139727</td>\n",
       "      <td>0.058614</td>\n",
       "      <td>0.715444</td>\n",
       "      <td>1.998464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038537</td>\n",
       "      <td>0.034171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635051</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>0.394440</td>\n",
       "      <td>1.374968</td>\n",
       "      <td>0.423758</td>\n",
       "      <td>0.123072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520479</td>\n",
       "      <td>1.790056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>1.138621</td>\n",
       "      <td>0.764802</td>\n",
       "      <td>0.404869</td>\n",
       "      <td>0.101241</td>\n",
       "      <td>0.115668</td>\n",
       "      <td>2.456570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143507</td>\n",
       "      <td>0.051275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.243723</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.029916</td>\n",
       "      <td>0.138603</td>\n",
       "      <td>0.508234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010886</td>\n",
       "      <td>0.553419</td>\n",
       "      <td>0.797945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498926</td>\n",
       "      <td>1.418822</td>\n",
       "      <td>0.255749</td>\n",
       "      <td>0.177682</td>\n",
       "      <td>0.036213</td>\n",
       "      <td>0.630050</td>\n",
       "      <td>3.494973</td>\n",
       "      <td>0.020767</td>\n",
       "      <td>0.411471</td>\n",
       "      <td>0.109544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.358602</td>\n",
       "      <td>1.168970</td>\n",
       "      <td>0.011796</td>\n",
       "      <td>0.375434</td>\n",
       "      <td>0.451893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.781089</td>\n",
       "      <td>0.898645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419094</td>\n",
       "      <td>0.972701</td>\n",
       "      <td>0.079639</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.450286</td>\n",
       "      <td>2.476288</td>\n",
       "      <td>0.077254</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.075810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.655848</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.174315</td>\n",
       "      <td>0.536645</td>\n",
       "      <td>0.441082</td>\n",
       "      <td>0.223644</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.612111</td>\n",
       "      <td>1.827969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078204</td>\n",
       "      <td>0.123453</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.623986</td>\n",
       "      <td>1.193960</td>\n",
       "      <td>0.357489</td>\n",
       "      <td>2.774895</td>\n",
       "      <td>0.182672</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>0.200875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6     \\\n",
       "0   0.287210  0.194326  0.000000  0.106927  0.377418  0.000000  0.620755   \n",
       "1   0.164605  0.000000  0.083406  0.048911  0.890236  0.018433  0.200687   \n",
       "2   0.284990  0.725162  0.144099  0.000000  1.011460  0.234903  0.137286   \n",
       "3   1.449418  0.169543  0.021138  0.288096  0.090404  0.024157  0.286722   \n",
       "4   0.349064  1.007837  0.033174  0.025766  0.156556  0.094527  0.040377   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "59  0.110216  0.701317  0.025022  0.334997  0.619999  0.229831  0.173924   \n",
       "60  0.000000  0.635051  0.071822  0.394440  1.374968  0.423758  0.123072   \n",
       "61  0.243723  0.783589  0.029916  0.138603  0.508234  0.000000  0.000000   \n",
       "62  0.358602  1.168970  0.011796  0.375434  0.451893  0.000000  0.057861   \n",
       "63  0.655848  0.050781  0.174315  0.536645  0.441082  0.223644  0.000977   \n",
       "\n",
       "        7         8         9     ...      2038      2039      2040      2041  \\\n",
       "0   1.064226  0.389456  0.584565  ...  0.000000  0.859810  0.449728  0.004866   \n",
       "1   1.360367  0.745493  0.273739  ...  0.000000  3.485157  1.629335  0.131944   \n",
       "2   0.140909  0.525270  0.112858  ...  0.000000  0.765385  0.189988  0.413721   \n",
       "3   0.000000  0.074135  0.751390  ...  0.119580  0.499493  0.000000  0.444929   \n",
       "4   0.251204  0.420903  0.316148  ...  0.048996  0.051137  0.253719  0.407803   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "59  0.000000  0.084275  1.449711  ...  0.051454  0.626314  0.000000  0.139727   \n",
       "60  0.000000  0.520479  1.790056  ...  0.005199  1.138621  0.764802  0.404869   \n",
       "61  0.010886  0.553419  0.797945  ...  0.498926  1.418822  0.255749  0.177682   \n",
       "62  0.000000  1.781089  0.898645  ...  0.000000  0.419094  0.972701  0.079639   \n",
       "63  0.005634  0.612111  1.827969  ...  0.078204  0.123453  0.003787  0.623986   \n",
       "\n",
       "        2042      2043      2044      2045      2046      2047  \n",
       "0   0.488186  0.763559  0.035749  0.983304  0.177645  1.678068  \n",
       "1   0.364728  0.145867  0.198063  0.210250  0.037983  0.701566  \n",
       "2   0.135747  0.167251  0.011636  0.936026  0.042564  0.453454  \n",
       "3   0.000000  1.681070  0.029463  0.545889  0.082474  0.422505  \n",
       "4   0.068843  0.005900  0.171881  0.292069  0.025903  0.043729  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "59  0.058614  0.715444  1.998464  0.000000  0.038537  0.034171  \n",
       "60  0.101241  0.115668  2.456570  0.000000  0.143507  0.051275  \n",
       "61  0.036213  0.630050  3.494973  0.020767  0.411471  0.109544  \n",
       "62  0.031499  0.450286  2.476288  0.077254  0.027223  0.075810  \n",
       "63  1.193960  0.357489  2.774895  0.182672  0.178126  0.200875  \n",
       "\n",
       "[64 rows x 2048 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged_ExtractedFeature_Clinical_DF.iloc[:,:2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "89a23ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sex(F/M)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Position</th>\n",
       "      <th>Label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Composition(Solid,pSolid,pCystic,Cyst)</th>\n",
       "      <th>Echogenicity(MarkedHypo,MildHypo,Isoecho,Hyperecho)</th>\n",
       "      <th>MicroCalcification(None/Presence)</th>\n",
       "      <th>MacroCalcification(None/Presence)</th>\n",
       "      <th>RimCalcification(None/Presence)</th>\n",
       "      <th>Margin(Smooth,Spiculated,illDefined)</th>\n",
       "      <th>Shape(Parallel,nonParallel)</th>\n",
       "      <th>Spongiform(None/Presence)</th>\n",
       "      <th>TailArtifact(None/Presence)</th>\n",
       "      <th>TIRADS_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-0002-1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001-0002-1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001-0003-1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001-0003-1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001-0003-1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>001-0018-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>001-0018-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>001-0018-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>001-0018-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>001-0018-1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subject  Sex(F/M)  Age  Diameter Position  Label  Location  \\\n",
       "0   001-0002-1         1   32        11        R      0         3   \n",
       "1   001-0002-1         1   32        11        R      0         3   \n",
       "2   001-0003-1         1   54        13        R      0         2   \n",
       "3   001-0003-1         1   54        13        R      0         2   \n",
       "4   001-0003-1         1   54        13        R      0         2   \n",
       "..         ...       ...  ...       ...      ...    ...       ...   \n",
       "59  001-0018-1         2   33        15        L      1         5   \n",
       "60  001-0018-1         2   33        15        L      1         5   \n",
       "61  001-0018-1         2   33        15        L      1         5   \n",
       "62  001-0018-1         2   33        15        L      1         5   \n",
       "63  001-0018-1         2   33        15        L      1         5   \n",
       "\n",
       "    Composition(Solid,pSolid,pCystic,Cyst)  \\\n",
       "0                                        1   \n",
       "1                                        1   \n",
       "2                                        2   \n",
       "3                                        2   \n",
       "4                                        2   \n",
       "..                                     ...   \n",
       "59                                       1   \n",
       "60                                       1   \n",
       "61                                       1   \n",
       "62                                       1   \n",
       "63                                       1   \n",
       "\n",
       "    Echogenicity(MarkedHypo,MildHypo,Isoecho,Hyperecho)  \\\n",
       "0                                                   3     \n",
       "1                                                   3     \n",
       "2                                                   3     \n",
       "3                                                   3     \n",
       "4                                                   3     \n",
       "..                                                ...     \n",
       "59                                                  1     \n",
       "60                                                  1     \n",
       "61                                                  1     \n",
       "62                                                  1     \n",
       "63                                                  1     \n",
       "\n",
       "    MicroCalcification(None/Presence)  MacroCalcification(None/Presence)  \\\n",
       "0                                   1                                  1   \n",
       "1                                   1                                  1   \n",
       "2                                   1                                  1   \n",
       "3                                   1                                  1   \n",
       "4                                   1                                  1   \n",
       "..                                ...                                ...   \n",
       "59                                  2                                  1   \n",
       "60                                  2                                  1   \n",
       "61                                  2                                  1   \n",
       "62                                  2                                  1   \n",
       "63                                  2                                  1   \n",
       "\n",
       "    RimCalcification(None/Presence)  Margin(Smooth,Spiculated,illDefined)  \\\n",
       "0                                 1                                     1   \n",
       "1                                 1                                     1   \n",
       "2                                 1                                     3   \n",
       "3                                 1                                     3   \n",
       "4                                 1                                     3   \n",
       "..                              ...                                   ...   \n",
       "59                                1                                     2   \n",
       "60                                1                                     2   \n",
       "61                                1                                     2   \n",
       "62                                1                                     2   \n",
       "63                                1                                     2   \n",
       "\n",
       "    Shape(Parallel,nonParallel)  Spongiform(None/Presence)  \\\n",
       "0                             1                          1   \n",
       "1                             1                          1   \n",
       "2                             1                          1   \n",
       "3                             1                          1   \n",
       "4                             1                          1   \n",
       "..                          ...                        ...   \n",
       "59                            1                          1   \n",
       "60                            1                          1   \n",
       "61                            1                          1   \n",
       "62                            1                          1   \n",
       "63                            1                          1   \n",
       "\n",
       "    TailArtifact(None/Presence)  TIRADS_Score  \n",
       "0                             1             3  \n",
       "1                             1             3  \n",
       "2                             1             3  \n",
       "3                             1             3  \n",
       "4                             1             3  \n",
       "..                          ...           ...  \n",
       "59                            1             5  \n",
       "60                            1             5  \n",
       "61                            1             5  \n",
       "62                            1             5  \n",
       "63                            1             5  \n",
       "\n",
       "[64 rows x 17 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Merged_ExtractedFeature_Clinical_DF.iloc[:,2048:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1222430b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.28 s\n",
      "Wall time: 1.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c7424aa1a0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fit = umap.UMAP()\n",
    "%time u = fit.fit_transform(Merged_ExtractedFeature_Clinical_DF.iloc[:,:2048])\n",
    "plt.scatter(u[:,0], u[:,1], c=IntegratedDF['Label'], cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d211c4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.14 s\n",
      "Wall time: 1.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c74197a380>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fit = umap.UMAP()\n",
    "%time u = fit.fit_transform(Merged_ExtractedFeature_Clinical_DF.iloc[:,:2048])\n",
    "plt.scatter(u[:,0], u[:,1], c=IntegratedDF['Composition(Solid,pSolid,pCystic,Cyst)'], cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1c4ca82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.27 s\n",
      "Wall time: 1.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c742a41960>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fit = umap.UMAP()\n",
    "%time u = fit.fit_transform(Merged_ExtractedFeature_Clinical_DF.iloc[:,:2048])\n",
    "plt.scatter(u[:,0], u[:,1], c=IntegratedDF['Margin(Smooth,Spiculated,illDefined)'], cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
